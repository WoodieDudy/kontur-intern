{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлечение ключевого фрагмента из текста с помощью NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке я дообучаю модель для выделения ключевых фрагментов из текста. Ключевые фрагменты можно рассматривать как именованные сущности, тогда задача будет называться NER. \n",
    "И сведется к классификации отдельных слов.\n",
    "\n",
    "Данный пайплайн в целом подходит для любой задачи на выделение сущностей в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# чтобы удобно подгружать nlp модели из большого открытого хаба\n",
    "# и удобно предобработывать тексты, взял transformers от HuggingFace\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# Для оберток над train loop и датасетов взял pytorch_lightning, тк был знаком с ним ранее\n",
    "# хотя было бы логичнее по возможности испльзовать альтернативы из transformers\n",
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# во время pytorch_lightning training loop вылезает предупреждение\n",
    "# которое просит отключить эту штуку\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для хранинения и параметов эксперимента написал свой класс конфига, чтобы удобно хранить их в yaml  \n",
    "и парсить в объект с типизированными полями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.config' from '/home/gk/projects/kontur/solution/helpers/config.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# при изменении структуры конфига надо переимпортировать его\n",
    "import importlib\n",
    "import helpers.config as config\n",
    "importlib.reload(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем конфиг и зададим сид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = config.Config.from_yaml_file(Path(\"./train_config.yml\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели для начала я взял предобученный на русской Википедии [BERT (rubert-base-cased) от DeepPavlov](https://huggingface.co/DeepPavlov/rubert-base-cased) на 180M параметров.\n",
    "Он показал себя хорошо, поэтому я не стал тратить время тест других.\n",
    "Также можно было бы еще поэкспериментировать с другими версиями BERT из HuggingFace хаба.\n",
    "Например с [rubert-tiny](https://huggingface.co/cointegrated/rubert-tiny) или [rubert-tiny2-finetuned-ner](https://huggingface.co/Evolett/rubert-tiny2-finetuned-ner).\n",
    "Хотя из-за их размера точность скорее всего была бы хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"data\": {\n",
       "        \"train_data_path\": \"./data/train.json\",\n",
       "        \"test_data_path\": \"./data/test.json\",\n",
       "        \"split\": [\n",
       "            0.7,\n",
       "            0.2,\n",
       "            0.1\n",
       "        ]\n",
       "    },\n",
       "    \"model\": {\n",
       "        \"model_name\": \"DeepPavlov/rubert-base-cased\",\n",
       "        \"unfreeze_layers\": [\n",
       "            \"encoder.layer.10\",\n",
       "            \"encoder.layer.11\"\n",
       "        ]\n",
       "    },\n",
       "    \"training\": {\n",
       "        \"project_name\": \"kontur-text-extraction\",\n",
       "        \"experiment_name\": \"exp6-final-test\",\n",
       "        \"description\": \"training to be displaed in notebook\",\n",
       "        \"batch_size\": 32,\n",
       "        \"epochs\": 30,\n",
       "        \"precision\": 16,\n",
       "        \"seed\": 42\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем рандом для воспроизводимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "pl.seed_everything(CONFIG.training.seed, workers=True)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для аннотации был использован немного измененный [BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) формат. Тк в нашей задаче сущности относительно длинные, а итоговая метрика accuracy очень чувствительна даже к одному лишнему символу, я добавил дополнительный тэг окончания **E-{name}**, посчитав, что так модель будет уделять больше внимания предсказанию конца фразы. Также с тэгом E будет удобнее доставать предсказание из текста, тк мы просто сможем выбрать самый вероятный токен для начала и окончания фразы.  \n",
    "  \n",
    "Короткие названия для запросов, которые я далее буду использовать:  \n",
    "* EXEC  - обеспечение исполнения контракта\n",
    "* GUAR - обеспечение гарантийных обязательств"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['O', 'B-EXEC', 'B-GUAR', 'I-EXEC', 'I-GUAR', 'E-EXEC', 'E-GUAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим токенайзер из HuggingFace хаба, соответствующий модели, которуя я выбрал\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.model.model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заранее токенизируем запросы и посчитаем их длину в токенах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tokenized = {\n",
    "    \"EXEC\": {\n",
    "        \"data\": tokenizer(\n",
    "            \"обеспечение исполнения контракта\", # вот строка запроса\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    },\n",
    "    \"GUAR\": {\n",
    "        \"data\": tokenizer(\n",
    "        \"обеспечение гарантийных обязательств\", # и вот\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    },\n",
    "}\n",
    "\n",
    "labels_tokenized[\"EXEC\"][\"len\"] = len(labels_tokenized['EXEC'][\"data\"]['input_ids'][0])\n",
    "labels_tokenized[\"GUAR\"][\"len\"] = len(labels_tokenized['GUAR'][\"data\"]['input_ids'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем трейн данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG.data.train_data_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на 4 выборки: трейн, вал, и две тестовые  \n",
    "Первая тестовая выборка нужна чтобы проверить качество модели именно на предобработанных данных.  \n",
    "Вторая - на сырых  \n",
    "Если бы я тестировал модель только на одной выборке, то при плохих результах я бы не мог с уверенностью сказать,  \n",
    "это модель плохо обучились или мой подход к инференсу работает плохо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер итоговой тестовой выборки: 180\n",
      "Размер обучающей выборки: 1133\n",
      "Размер валидационной выборки: 324\n",
      "Размер тестовой выборки: 162\n"
     ]
    }
   ],
   "source": [
    "val_size = CONFIG.data.split[1] / sum(CONFIG.data.split[1:])\n",
    "\n",
    "# детерминированно перемешиваем\n",
    "temp_data, final_test_data = train_test_split(data, test_size=CONFIG.data.split[2], shuffle=True, random_state=CONFIG.training.seed)\n",
    "train_data, temp_data = train_test_split(temp_data, train_size=CONFIG.data.split[0], shuffle=False)\n",
    "val_data, test_data = train_test_split(temp_data, train_size=val_size, shuffle=False)\n",
    "print(f\"Размер итоговой тестовой выборки: {len(final_test_data)}\")\n",
    "print(f\"Размер обучающей выборки: {len(train_data)}\")\n",
    "print(f\"Размер валидационной выборки: {len(val_data)}\")\n",
    "print(f\"Размер тестовой выборки: {len(test_data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я формирую датасет и каждому токену из предложения сопоставляю тэг.  \n",
    "Тк большинство предоставленных текстов содержат больше чем 512 токенов, их придется поделить на куски поменьше,  \n",
    "чтобы BERT мог с ними работать.  \n",
    "Для этого беру рандомные срезы вокруг фразы которую нужно вытащить, длины не более 400 (на всякий случай).  \n",
    "Срезы беру вокруг фраз, чтобы не обрезать их (чтобы в сэмпле всегда было конец и начало).  \n",
    "Мне кажется, что модели будет сложнее будет правильно выделить фразу в обрезанном тексте, особенно, если было обрезано начало искомой фразы. На инференсе я учту, что модель училась на \"хороших\" сэмплах  \n",
    "Потом добавляю к каждому получившемуся сэмплу токены из запроса.  \n",
    "Получится типо того:  \n",
    "\"обеспечение исполнения контракта [SEP] ТРЕБОВАНИЯ К СОДЕРЖАНИЮ ЗАЯВКИ участника запроса котир...\"  \n",
    "  \n",
    "Тк нам нужно искать сущности разного типа в разных случаях, и мы хотим делать это одной моделью, мы как бы сообщаем модели, что вообще она должна найти и она учитывает это при предсказании токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utils import generate_positive_slices, generate_negative_slices, pad_to_length, find_value_in_list\n",
    "\n",
    "\n",
    "def preprocess_data(raw_data):\n",
    "    tokenized_data = []\n",
    "    for item in tqdm(raw_data):\n",
    "        text = item['text']\n",
    "        label = item['label']\n",
    "        extracted_part = item['extracted_part']\n",
    "        answer_start_symbol_idx = extracted_part['answer_start'][0]\n",
    "        answer_end_symbol_idx = extracted_part['answer_end'][0]\n",
    "        \n",
    "        # для большей понятность заменяю 0 на -1\n",
    "        if answer_start_symbol_idx == 0 and answer_end_symbol_idx == 0:\n",
    "            answer_start_symbol_idx, answer_end_symbol_idx = -1, -1\n",
    "\n",
    "        if label == 'обеспечение исполнения контракта':\n",
    "            short_label = 'EXEC'\n",
    "        else:\n",
    "            short_label = 'GUAR'\n",
    "\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        token_tag_ids = []\n",
    "        # беру индекс начала и конца каждого токена и смотрю где он находится\n",
    "        for i, token_offset in enumerate(encoding['offset_mapping'][0]):\n",
    "            token_start, token_end = token_offset[0], token_offset[1]\n",
    "\n",
    "            # если индекс символа начала фразы внутри токена, то токен является началом (B)\n",
    "            if token_start <= answer_start_symbol_idx <= token_end:\n",
    "                token_tag_ids.append(tags.index(f\"B-{short_label}\"))\n",
    "            \n",
    "            # если индекс символа конца фразы внутри токена, то токен является концом (E)\n",
    "            elif token_start <= answer_end_symbol_idx <= token_end:\n",
    "                token_tag_ids.append(tags.index(f\"E-{short_label}\"))\n",
    "\n",
    "            # если токен находися между началом и концом, то он внутренний (I)\n",
    "            elif answer_start_symbol_idx <= token_start and token_end <= answer_end_symbol_idx:\n",
    "                token_tag_ids.append(tags.index(f\"I-{short_label}\"))\n",
    "\n",
    "            # иначе токен внешний и не принадлежит фразе\n",
    "            else:\n",
    "                token_tag_ids.append(tags.index(\"O\"))\n",
    "        \n",
    "\n",
    "        sentence_len = len(token_tag_ids)\n",
    "\n",
    "        # ищу индекс конца и начала фразы в списле с тегами токенов\n",
    "        start_idx = find_value_in_list(token_tag_ids, tags.index(f\"B-{short_label}\"))\n",
    "        end_idx = find_value_in_list(token_tag_ids, tags.index(f\"E-{short_label}\"))\n",
    "\n",
    "        # генерирую индексы срезов содержащих фразу и без искомой фразы\n",
    "        positive_slices = generate_positive_slices(start_idx, end_idx, n=5, max_length=400)\n",
    "        negative_slices = generate_negative_slices(start_idx, end_idx, sentence_len, 2, 200, 400)\n",
    "\n",
    "        final_seq_len = 512 # в итоге хотим получить тексты длинной 512 токенов\n",
    "        for start, end in positive_slices + negative_slices:\n",
    "            # собираю вместе инфромацию из токенайзера для каждого среза\n",
    "            data = [\n",
    "                pad_to_length(torch.cat(( # делаю паддинг тензоров до длины final_seq_len\n",
    "                    labels_tokenized[short_label][\"data\"]['input_ids'][0], # добавляю токены из запроса\n",
    "                    encoding['input_ids'][0][start:end], # беру токены с номерами от start до end из сгенерированнх срезов\n",
    "                )),final_seq_len, 0),\n",
    "                pad_to_length(torch.cat((\n",
    "                    labels_tokenized[short_label][\"data\"]['token_type_ids'][0],\n",
    "                    encoding['token_type_ids'][0][start:end],\n",
    "                )),final_seq_len, 0),\n",
    "                pad_to_length(torch.cat((\n",
    "                    labels_tokenized[short_label][\"data\"]['attention_mask'][0],\n",
    "                    encoding['attention_mask'][0][start:end],\n",
    "                )),final_seq_len, 0),\n",
    "                pad_to_length(torch.cat((\n",
    "                    # токены запроса обозначаю как внешние, можно было бы попробовать выделить из в отдельный класс Q\n",
    "                    torch.tensor([tags.index(\"O\")] * labels_tokenized[short_label][\"len\"]),\n",
    "                    torch.tensor(token_tag_ids[start:end],)\n",
    "                )), final_seq_len, tags.index(\"O\"))\n",
    "            ]\n",
    "\n",
    "            tokenized_data.append(data)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb87ef6aaa64f2982ae2aac2050732c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754e3abe26db44a197436d85bd4b2b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de7f909ea4f43b98ce47f3aa53c5ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок, после препроцессинга\n",
      "Размер обучающей выборки: 6919\n",
      "Размер валидационной выборки: 1966\n",
      "Размер тестовой выборки: 1020\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_data = preprocess_data(train_data)\n",
    "tokenized_val_data = preprocess_data(val_data)\n",
    "tokenized_test_data = preprocess_data(test_data)\n",
    "print(\"Размеры выборок, после препроцессинга\")\n",
    "print(f\"Размер обучающей выборки: {len(tokenized_train_data)}\")\n",
    "print(f\"Размер валидационной выборки: {len(tokenized_val_data)}\")\n",
    "print(f\"Размер тестовой выборки: {len(tokenized_test_data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как сгенерировался датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_train_data[idx][0])\n",
    "token_tags = [tags[i] for i in tokenized_train_data[idx][3]]\n",
    "df = pd.DataFrame({'Tokens': tokens[200:221], 'Tags': token_tags[200:221]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>.</td>\n",
       "      <td>Обеспеч</td>\n",
       "      <td>##ение</td>\n",
       "      <td>исполнения</td>\n",
       "      <td>Договора</td>\n",
       "      <td>устанавливается</td>\n",
       "      <td>в</td>\n",
       "      <td>размере</td>\n",
       "      <td>5</td>\n",
       "      <td>процент</td>\n",
       "      <td>...</td>\n",
       "      <td>ов</td>\n",
       "      <td>,</td>\n",
       "      <td>а</td>\n",
       "      <td>)</td>\n",
       "      <td>Цены</td>\n",
       "      <td>Договора</td>\n",
       "      <td>.</td>\n",
       "      <td>9</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>...</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>I-EXEC</td>\n",
       "      <td>E-EXEC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2           3         4                5       6   \\\n",
       "Tokens  .  Обеспеч  ##ение  исполнения  Договора  устанавливается       в   \n",
       "Tags    O   B-EXEC  I-EXEC      I-EXEC    I-EXEC           I-EXEC  I-EXEC   \n",
       "\n",
       "             7       8        9   ...      11      12      13      14      15  \\\n",
       "Tokens  размере       5  процент  ...      ов       ,       а       )    Цены   \n",
       "Tags     I-EXEC  I-EXEC   I-EXEC  ...  I-EXEC  I-EXEC  I-EXEC  I-EXEC  I-EXEC   \n",
       "\n",
       "              16      17 18 19 20  \n",
       "Tokens  Договора       .  9  .  2  \n",
       "Tags      I-EXEC  E-EXEC  O  O  O  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TextExtractionDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "\n",
    "class TextExtractionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = 4\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_data = TextExtractionDataset(tokenized_train_data)\n",
    "        self.val_data = TextExtractionDataset(tokenized_val_data)\n",
    "        self.test_data = TextExtractionDataset(tokenized_test_data)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=self.num_workers)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обертку опять использовал lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модель добавляем линейный слой для классификации каждого токена на 7 классов.  \n",
    "Часть весов модели замораживается для уменьшения количества обучаемых параметров.  \n",
    "В качестве лосса взята CE с весами, как база для классификации  \n",
    "Оптимизатором выбран Adam, тк тоже база  \n",
    "Scheduler взял LinearLR, тк с ним завелось нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "class BertForTextExtraction(pl.LightningModule):\n",
    "    def __init__(self, model_name=None, lr=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        # вынесл lr чтобы его можно было подобрать с помощью auto_lr_find\n",
    "        self.lr = lr\n",
    "        # подгрузитм предобученный берт\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        # добавим линейный слой для классификации каждого токена на 7 классов\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, len(tags))\n",
    "\n",
    "        # заморозим часть вестов, чтобы не обучать модель полностью\n",
    "        self.freeze_bert_layers()\n",
    "        \n",
    "        # в качестве лосса берем базовый CE\n",
    "        # веса для классов для добавил по интуиции, тк кажется что надо больше сфокусироваться на предсказании конца и начала фразы\n",
    "        # Конец предсказывать сложнее, поэтому вес больше \n",
    "        # Порядок: ['O', 'B-EXEC', 'B-GUAR', 'I-EXEC', 'I-GUAR', 'E-EXEC', 'E-GUAR']\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=torch.tensor([1/20, 1, 1, 1/4, 1/4, 4, 4]))\n",
    "\n",
    "    def freeze_bert_layers(self):\n",
    "        # Заморозим все слои, кроме тех, которые указаты в кофиге\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            if name.startswith(tuple(CONFIG.model.unfreeze_layers)):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # линейные слои тоже оставим в тепле\n",
    "        for param in self.linear.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        bert_output = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "\n",
    "        return self.linear(sequence_output).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, token_type_ids, attention_mask, token_tags = batch\n",
    "\n",
    "        # зарешейпим тензоры в подходящий для torch.CE размер\n",
    "        logits = self.forward(input_ids, token_type_ids, attention_mask).reshape(-1, len(tags)) # (batch_size, 512, 7) -> (batch_size * 512, 7)\n",
    "        token_tags = token_tags.reshape(-1) # (batch_size, 512) -> (batch_size * 512)\n",
    "\n",
    "        loss = self.criterion(logits, token_tags)\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, token_type_ids, attention_mask, token_tags = batch\n",
    "        logits = self.forward(input_ids, token_type_ids, attention_mask).reshape(-1, len(tags))\n",
    "        token_tags = token_tags.reshape(-1)\n",
    "        \n",
    "        loss = self.criterion(logits, token_tags)\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        tp = 0\n",
    "        input_ids, token_type_ids, attention_mask, token_tags = batch\n",
    "        # сделаем предикт\n",
    "        logits = self.forward(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # бежим по батчу\n",
    "        for i in range(len(batch)):\n",
    "            if tags.index('B-EXEC') in token_tags[i] and tags.index('E-EXEC') in token_tags[i]:\n",
    "                start_num = tags.index('B-EXEC')\n",
    "                end_num = tags.index('E-EXEC')\n",
    "            elif tags.index('B-GUAR') in token_tags[i] and tags.index('E-GUAR') in token_tags[i]:\n",
    "                start_num = tags.index('B-GUAR')\n",
    "                end_num = tags.index('E-GUAR')\n",
    "            else:\n",
    "                # тут по хорошему надо протестить с обоими тэгами, но я не успел\n",
    "                start_num = tags.index('B-EXEC')\n",
    "                end_num = tags.index('E-EXEC')\n",
    "\n",
    "            # достанем самые вероятные начало и конец\n",
    "            pred_start = torch.argmax(logits[i, :, start_num]).item()\n",
    "            pred_end = torch.argmax(logits[i, :, end_num]).item()\n",
    "            \n",
    "            # если у одного из токенов самый вероятный класс это не начало или конец соответственно\n",
    "            # то забаним все предложение\n",
    "            if torch.argmax(logits[i, pred_start]) != start_num:\n",
    "                pred_start, pred_end = 0, 0\n",
    "            if torch.argmax(logits[i, pred_end]) != end_num:\n",
    "                pred_start, pred_end = 0, 0\n",
    "\n",
    "            try: # если проблема с индексами, то значит в этом сэмпле пусто\n",
    "                # тк одно слово может распасться на несколько токенов для start возьмем номер первого токена [0]\n",
    "                real_start = torch.where(token_tags[i] == start_num)[0][0].item()         \n",
    "                # а для end номер последнего токена [-1]\n",
    "                real_end = torch.where(token_tags[i] == end_num)[0][-1].item()\n",
    "            except IndexError:\n",
    "                real_start, real_end = 0, 0\n",
    "\n",
    "            if pred_start == real_start and pred_end == real_end:\n",
    "                tp += 1\n",
    "\n",
    "        return {\n",
    "            \"acc\": tp,\n",
    "            \"batch_len\": len(batch), # также вернем количество сэпилов на которых проверяли\n",
    "        }\n",
    "\n",
    "    # посчитаем итоговый accuracy\n",
    "    def test_epoch_end(self, outputs):\n",
    "        metrics = {\n",
    "            \"acc\": 0,\n",
    "        }\n",
    "        test_loader_len = 0\n",
    "        for batch in outputs:\n",
    "            test_loader_len += batch[\"batch_len\"]\n",
    "            for key in metrics:\n",
    "                metrics[key] += batch[key]\n",
    "\n",
    "        for key in metrics:\n",
    "            metrics[key] /= test_loader_len\n",
    "\n",
    "        print(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.lr) # в качестве оптимизоватора возьмем просто Adam. тк работает\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR( # со scheduler'ами тоже можно было бы поэкспериментировать\n",
    "            optimizer=optimizer,\n",
    "            start_factor=1,\n",
    "            end_factor=0.00001,\n",
    "            total_iters=10_000,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = TextExtractionDataModule(batch_size=CONFIG.training.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем веса модельки, которую я обучил  \n",
    "Веса положил на гугл диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File rubert-base-cased-ner-kontur.ckpt already exists in the weights/ directory. No need to download.\n"
     ]
    }
   ],
   "source": [
    "!bash download_weights.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут можно выбрать, взять уже обученную на всех данных мною модель  \n",
    "или претрейн от DeepPavlov, с которого я тренировал модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad5542f1150408f94c34fcf525376bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Выберите веса', options=('Не выбрано', 'Обученная модель', 'Претрейн от DeepPavlov'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Взяты претрейн веса\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=['Не выбрано', 'Обученная модель', 'Претрейн от DeepPavlov'],\n",
    "    value='Не выбрано',\n",
    "    description='Выберите веса',\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global model\n",
    "        if change['new'] == 'Обученная модель':\n",
    "            path = \"weights/rubert-base-cased-ner-kontur.ckpt\"\n",
    "            model = BertForTextExtraction.load_from_checkpoint(path, model_name=CONFIG.model.model_name)\n",
    "            print(f\"Взяты веса из {path}\")\n",
    "        elif change['new'] == 'Претрейн от DeepPavlov':\n",
    "            model = BertForTextExtraction(CONFIG.model.model_name)\n",
    "            print(\"Взяты претрейн веса\")\n",
    "        else:\n",
    "            print(\"Выберете еще раз\")\n",
    "\n",
    "dropdown.observe(on_change)\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим Trainer. Он будет сохранять лучший чекпоит по train_loss и отдельно по val_loss, а также просто последний чекпоинт  \n",
    "Метрики будут логироваться в wandb (для этого надо авторизироваться командой ниже, или закомментить логгер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login <your_token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir='./checkpoints/lr/',\n",
    "    log_every_n_steps=10,\n",
    "    precision=CONFIG.training.precision,\n",
    "    auto_lr_find=True,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    max_epochs=CONFIG.training.epochs,\n",
    "    logger=pl.loggers.WandbLogger( # это можно закомментить\n",
    "        project=CONFIG.training.project_name,\n",
    "        name=CONFIG.training.experiment_name,\n",
    "        config=CONFIG.to_dict(),\n",
    "    ),\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{CONFIG.training.experiment_name}', filename='epoch={epoch}-val_loss={val/loss:.2f}',\n",
    "            monitor='val/loss', save_top_k=1, mode='min', auto_insert_metric_name=False),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{CONFIG.training.experiment_name}', filename='epoch={epoch}-train_loss={train/loss:.2f}',\n",
    "            monitor='train/loss', save_top_k=1, mode='min', auto_insert_metric_name=False),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{CONFIG.training.experiment_name}', filename='epoch={epoch}-train_loss={train/loss:.2f}',\n",
    "            every_n_epochs=10, auto_insert_metric_name=False),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gk/envs/dsenv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/gk/projects/kontur/solution/checkpoints/exp6-final-test exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d0b5b6852c49819c77dc25f30fa355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gk/envs/dsenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 4.786300923226385e-05\n",
      "Restoring states from the checkpoint path at checkpoints/lr/.lr_find_4be8a57f-1ab0-48a4-b5bb-73974bf80240.ckpt\n",
      "Restored all states from the checkpoint file at checkpoints/lr/.lr_find_4be8a57f-1ab0-48a4-b5bb-73974bf80240.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr_find': <pytorch_lightning.tuner.lr_finder._LRFinder at 0x7f8780d7fca0>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.tune(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | bert      | BertModel        | 177 M \n",
      "1 | linear    | Linear           | 5.4 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "14.2 M    Trainable params\n",
      "163 M     Non-trainable params\n",
      "177 M     Total params\n",
      "355.718   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9954c5837e5648659e8cf4d528c15685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92efde88abed400db797df43c9cd497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6707e3d2c2ce4841a2e0d1a64615771d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7402a9aecc5541f99a441705b6038883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b38834aa3d4164a1f5a8cdf06c6687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c112454de93d4f2ebfa37fb813eed017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126639967f3a4242b14ba98bdc3438fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652e4994b2c24fd8bc15310bb12babd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a853496469b84e699bcf046f35335403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47141b9fe3d845a4ba1bd80b70380f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df802a712ce9446fa11f9e99c9eff9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4770be1951d49a7926cc65c4f1d60f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c341331e4a4c2f91be23d0e09bb382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90628dfe40e146b9bd409ea165458605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca517ba3e9bb459b9ece45bab9cceac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856ab35b0444770bbf449303068ef2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b84eb64f3d548f2b5128e58a053693c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1bf08bd2dd4b7982bb94788444d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa53213460d45368756d93b81831230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba74498da0fd45628a0e84730f61f017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918e0e63e5af48e699db69587a53b92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f75863e499d4693ba9399ddaf7997da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469d35f255b34e06933aa0ad3f62aba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95778d5680894e9f9cf360d2c84503b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b357d21c2814441a991cbd61cf34c842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f832c58e70c43989f262fa44f255cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fe1d8da6ce4734933f1bcb443a4118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005d367856c64feabd2e037980e37768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb416b2b8f64495e83b4f288e931678f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f6b55b620b46bc815b0df1b8cefd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00befba4f0546c2bc158c29abf51dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922f3a19141e4d4fbbbbc2d163878eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим точность на не пустых текстах из test dataloader'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gk/projects/kontur/solution/checkpoints/exp6-final-test/epoch=7-val_loss=0.09.ckpt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForTextExtraction.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path,\n",
    "    model_name=CONFIG.model.model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c12442cd1cf4393b66c9a031608179a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.71875}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценим точность на final_test_data, которую мы отложили в начале"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предсказания фразы на длинном тексте используется скользящее окно в 400 токенов, с шагом 100. Тоесть соседние окна будут пересекаться на 300 токенов.  \n",
    "Это сделанно для того, чтобы хотя бы в одном окне фраза попала от начала до конца (как в обучающей выборке)  \n",
    "За итоговый ответ я беру предсказанное начало и конец из того окна где уверенность токена начала + уверенность токена конца максимальна.  \n",
    "Также из если предсказанная фраза оканчивается на что-то из \",/:\" я удаляю этот символ, тк у модели не всегда получается их убирать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inference_data):\n",
    "    predictions = []\n",
    "    for item in tqdm(inference_data):\n",
    "        text = item['text']\n",
    "        label = item['label']\n",
    "\n",
    "        if label == 'обеспечение исполнения контракта':\n",
    "            short_label = 'EXEC'\n",
    "            start_num = 1\n",
    "            end_num = 5\n",
    "        else:\n",
    "            short_label = 'GUAR'\n",
    "            start_num = 2\n",
    "            end_num = 6\n",
    "\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        sentence_len = len(encoding['attention_mask'][0])\n",
    "        step = 100\n",
    "        window_size = 400\n",
    "        final_seq_len = 512\n",
    "\n",
    "        potential_answers = []\n",
    "\n",
    "        offset = 0\n",
    "        for i in range(0, sentence_len, step):\n",
    "            offset = i\n",
    "            data = (\n",
    "                pad_to_length(torch.cat((\n",
    "                    labels_tokenized[short_label][\"data\"]['input_ids'][0],\n",
    "                    encoding['input_ids'][0][i:i+window_size],\n",
    "                )), final_seq_len, 0).to(device).unsqueeze(0),\n",
    "                pad_to_length(torch.cat((\n",
    "                    labels_tokenized[short_label][\"data\"]['token_type_ids'][0],\n",
    "                    encoding['token_type_ids'][0][i:i+window_size],\n",
    "                )), final_seq_len, 0).to(device).unsqueeze(0),\n",
    "                pad_to_length(torch.cat((\n",
    "                    labels_tokenized[short_label][\"data\"]['attention_mask'][0],\n",
    "                    encoding['attention_mask'][0][i:i+window_size],\n",
    "                )), final_seq_len, 0).to(device).unsqueeze(0),\n",
    "            )\n",
    "            logits = model(*data)[0]\n",
    "            \n",
    "            # найдем токен у которого самая большая вероятность что он начало\n",
    "            pred_start_idx = torch.argmax(logits[:, start_num])\n",
    "            # если у этого токена самый вероятный класс это не начало, то пропустим все окно\n",
    "            # тк будем считать что в нем не находится начало\n",
    "            if torch.argmax(logits[pred_start_idx]) != start_num:\n",
    "                continue\n",
    "            pred_start_conf = logits[pred_start_idx, start_num]\n",
    "\n",
    "            # токен конца будем уже выбирать из токенов, которые идут за токеном начала (тк начало легче предсказывать)\n",
    "            pred_end_idx = torch.argmax(logits[pred_start_idx:, end_num]) + pred_start_idx\n",
    "            if torch.argmax(logits[pred_end_idx]) != end_num:\n",
    "                continue\n",
    "            pred_end_conf = logits[pred_end_idx, end_num]\n",
    "\n",
    "            # к индексам найденых токенов добавим сдиг окна\n",
    "            # и вычтем длинну запроса, который мы добавляли в начале каждого окна\n",
    "            pred_start_idx += offset - labels_tokenized[short_label][\"len\"]\n",
    "            pred_end_idx += offset - labels_tokenized[short_label][\"len\"]\n",
    "            # добавим найденную пару в потенциальные ответы\n",
    "            potential_answers.append((\n",
    "                pred_start_idx,\n",
    "                pred_end_idx,\n",
    "                pred_start_conf + pred_end_conf # в качестве уверенности ответа возьмем сумму уверенностей\n",
    "            ))\n",
    "\n",
    "        # достанем пару с самой большой уверенностью\n",
    "        if potential_answers:\n",
    "            best_borders = max(potential_answers, key=lambda x: x[2])\n",
    "        else:\n",
    "            # если ни одна паре на нашлась, то будут нули\n",
    "            best_borders = (0, 0)\n",
    "\n",
    "        # если тут вывалилась ошибка, то модель предсказала токен [PAD]\n",
    "        try:\n",
    "            # достанем индекс первого символа в токене начала\n",
    "            start_char_idx = encoding['offset_mapping'][0][best_borders[0]][0].item()\n",
    "            end_char_idx = encoding['offset_mapping'][0][best_borders[1]][1].item()\n",
    "        except:\n",
    "            # предположим, что ответа в тексте нет\n",
    "            start_char_idx, end_char_idx = 0, 0\n",
    "            # можно доработать и пребрать другие предположения из potential_answers TODO\n",
    "\n",
    "        pred = {\n",
    "            \"text\": [text[start_char_idx:end_char_idx]],\n",
    "            \"answer_start\": [start_char_idx],\n",
    "            \"answer_end\": [end_char_idx]\n",
    "        }\n",
    "        \n",
    "        if pred[\"text\"][0] != \"\":\n",
    "            # удалим лишние знаки\n",
    "            if pred[\"text\"][0][-1] in \",/:;-_\":\n",
    "                pred[\"text\"][0] = pred[\"text\"][0][:-1]\n",
    "                pred[\"answer_end\"][0] -= 1\n",
    "                \n",
    "            if pred[\"text\"][0][0] in [\".\"]:\n",
    "                pred[\"text\"][0] = pred[\"text\"][0][1:]\n",
    "                pred[\"answer_start\"][0] += 1\n",
    "\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0285bb075c704cc1ac94ea44f67513dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "data = final_test_data\n",
    "predictions = inference(data)\n",
    "tp = 0\n",
    "diff = []\n",
    "for gt, pred in zip(data, predictions):\n",
    "    if gt['extracted_part'] == pred:\n",
    "        tp += 1\n",
    "    else:\n",
    "        diff.append([gt[\"id\"], pred, gt['extracted_part']])\n",
    "\n",
    "\n",
    "print(tp / len(data))\n",
    "\n",
    "with open(\"diff.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(diff, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сгенерируем submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a73fff170db42d6989b19867e85cdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(CONFIG.data.test_data_path, encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "submission = []\n",
    "predictions = inference(data)\n",
    "for item, pred in zip(data, predictions):\n",
    "    item['extracted_part'] = pred\n",
    "    submission.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(submission, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
